{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# HW9 - Fine-tuning BERT!\n",
        "\n",
        "> ä»»å‹™: ä»¥BERTç‚ºåŸºç¤ï¼Œfine-tune å‡ºä¸€å€‹å¯ä»¥åˆ¤æ–·æ–‡ç« ã€Œæ˜¯å¦ç‚ºå»£å‘Šã€çš„æ¨¡å‹ï¼ˆlabel \"1\" ç‚ºå»£å‘Šã€\"0\"ç‚ºéå»£å‘Šï¼‰\n",
        "\n",
        "> è¨ˆåˆ†æ–¹å¼ï¼š\n",
        "1. Preprocessing (20%)\n",
        "2. Training and validating (30%)\n",
        "3. Predicting (20%)\n",
        "4. **æœ‰åšå…©çµ„ä»¥ä¸Šçš„å˜—è©¦** ï¼ˆ10%)ï¼ˆéœ€åœ¨Markdownå¯«å‡ºä½ å˜—è©¦çš„åƒæ•¸çµ„åˆåŠçµæœï¼‰\n",
        "5. å–Accuracyæœ€é«˜çš„çµæœï¼š(Acc - 0.8)x100\n",
        "   ä¾‹å¦‚ä½ æœ€å¥½çš„modelæ­£ç¢ºç‡æœ‰0.88ï¼Œé‚£ä½ å°±æœƒå†åŠ ä¸Š(0.88-0.8)x100=8åˆ†ï¼"
      ],
      "metadata": {
        "id": "bUhZz0QTurYo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "çµ¦å®štrain_dfå’Œtest_dfå…©ä»½è³‡æ–™ï¼Œå…¶ä¸­train_dfç‚º4000ç­†æœªç¶“å‰è™•ç†çš„è³‡æ–™ï¼Œtest_dfç‚º1000ç­†æ¸…ç†ä¹¾æ·¨çš„è³‡æ–™ã€‚"
      ],
      "metadata": {
        "id": "jpuZFtj1wEEN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Preprocessing steps with BERT \n",
        "\n",
        "ğŸ’ª pretrained modelè«‹ä½¿ç”¨\"bert-base-chinese\" & BertForSequenceClassification (è¨­å®šå¦‚ä¸‹æ‰€ç¤ºï¼‰\n",
        "\n",
        "ğŸ’ª \n",
        "å‰è™•ç†æ­¥é©Ÿ\n",
        "\n",
        "1. åŠ å…¥special tokens:\n",
        "  - [CLS]: æ¯å€‹å¥å­çš„é–‹é ­ (ID 101)\n",
        "  - [SEP]: æ¯å€‹å¥å­çš„çµå°¾ (ID 102)\n",
        "2. æ¯å€‹å¥å­é•·åº¦ç›¸ç­‰:\n",
        "  - è¨­å®šmaximum sequence lengthï¼Œæœ€å¤šå¯åˆ° 512 tokens\n",
        "  - Padding([PAD]) ï¼šä¸è¶³max lengthçš„å¥å­ä»¥ ID 0è£œæ»¿\n",
        "  - Truncated: å¤ªé•·çš„å¥å­å°±åˆ‡åˆ°max length\n",
        "3. Attention mask:\n",
        "  - List of 0/1 indicating whether the model should consider the tokens or not when learning their contextual representation. (special tokensä¹Ÿæ˜¯1ï¼Œåªæœ‰[PAD] tokensç‚º 0ï¼‰\n",
        "\n",
        "ä½¿ç”¨``tokenizer.encode_plus``é€™å€‹functionï¼Œå¾—åˆ°çµæœæœƒåŒ…å«:\n",
        "\n",
        "- input_ids: list of token IDs.\n",
        "- attention_mask: list of 0/1 indicating which tokens should be considered by the model (return_attention_mask = True).\n"
      ],
      "metadata": {
        "id": "vcZru24fWmlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "zKAPv3ded9R0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from tabulate import tabulate\n",
        "from tqdm import trange\n",
        "import random"
      ],
      "metadata": {
        "id": "NAY6Vre3d-m2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "b975e9f3-0fcf-425b-fe11-d482aae61104",
        "id": "f2eGv59ofmm_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  label\n",
              "0  Vé ˜è¨­è¨ˆèƒ½å¤ ä¿®é£¾è‡‰å‹ğŸ˜\\næ¸›é½¡æ³¡æ³¡è¢–æ´‹è£ğŸ˜‰\\nğŸ‘‰https://lihi1.com/JDym...      1\n",
              "1  ã€20210303ã€‘\\nèƒ½å‹‡æ•¢è¿½å¤¢çš„äºº\\nèº«ä¸Šéƒ½é–ƒè‘—å’Œç…¦çš„å…‰èŠ’\\nä¹Ÿæ˜¯å¥½ç”Ÿç¾¨æ…•ï¼\\n-\\næ•¬...      0\n",
              "2                             ç‰ è€³ç’°\\n#è€³ç’° #ç‰ #earrings      1\n",
              "3  ã€ç¾åœ‹ç˜‹æ½®WWE Taiwanã€‘\\nä¸ç®¡æ˜¯WWE Eliteé‚„æ˜¯AEW Unrivaledç³»...      1\n",
              "4  ğŸŒˆ\\nå°‹æ™šçš„post ä¸€poå·²ç¶“è¢«ç§’æ®ºå¥½å¤šä»¶çš„Vintage sports windbrea...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f54a574d-48f5-4196-a9c4-081f6cb9b36b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Vé ˜è¨­è¨ˆèƒ½å¤ ä¿®é£¾è‡‰å‹ğŸ˜\\næ¸›é½¡æ³¡æ³¡è¢–æ´‹è£ğŸ˜‰\\nğŸ‘‰https://lihi1.com/JDym...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ã€20210303ã€‘\\nèƒ½å‹‡æ•¢è¿½å¤¢çš„äºº\\nèº«ä¸Šéƒ½é–ƒè‘—å’Œç…¦çš„å…‰èŠ’\\nä¹Ÿæ˜¯å¥½ç”Ÿç¾¨æ…•ï¼\\n-\\næ•¬...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ç‰ è€³ç’°\\n#è€³ç’° #ç‰ #earrings</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ã€ç¾åœ‹ç˜‹æ½®WWE Taiwanã€‘\\nä¸ç®¡æ˜¯WWE Eliteé‚„æ˜¯AEW Unrivaledç³»...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ğŸŒˆ\\nå°‹æ™šçš„post ä¸€poå·²ç¶“è¢«ç§’æ®ºå¥½å¤šä»¶çš„Vintage sports windbrea...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f54a574d-48f5-4196-a9c4-081f6cb9b36b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f54a574d-48f5-4196-a9c4-081f6cb9b36b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f54a574d-48f5-4196-a9c4-081f6cb9b36b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "d561432f-de35-4dc5-ea78-f79384671f99",
        "id": "JHof_XYFfonH"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  label\n",
              "4000                                     æ˜¯é»‘æš—çš„é™½å…‰å°‘å¥³å§ä¼Šé”é‚µç¢¼é ­      0\n",
              "4001  æœ¬é€±æ–°å“çœŸçš„æ˜¯é¦¬ä¸åœè¹„çš„ä¸€é€±æ˜¥è£æ–°å“è¶Šä¾†è¶Šå¤šå¯¶å¯¶å®¢äººå€‘éƒ½è²·ä¸åœèº«ç‚ºå¥³å­©å¦³èƒ½æœ‰ä¸æ¼‚äº®çš„æ¬Šåˆ©å—è®“...      1\n",
              "4002                                      éœ§çœ‰ä½å®¶å·¥ä½œå®¤é ç´„å°ä¸­éœ§çœ‰      1\n",
              "4003  ä¸­é•·ç‰ˆæŒºæ–™è¥¿è£å¤–å¥—å…©å´å£è¢‹èˆ‡å¾®è…°èº«è¨­è¨ˆçœŸçš„å¾ˆç¾å¥¶æè‰²å¤©ç©ºè—å…±è‰²è‰å¸½å¥³å­©åœ–ç°¡ç´„åœ–ä¹Ÿæ˜¯æ™‚é«¦ç©¿æ­çš„...      1\n",
              "4004  ç”·ç”ŸæŸ“é«®ç„¦ç³–æ£•è‰²è³ªæ„Ÿä½èª¿çš„ç„¦ç³–è‰²è®“ç”·ç”Ÿé ­é«®ä¹Ÿèƒ½æœ‰ä¸ä¸€æ¨£çš„é¸æ“‡å–œæ­¡è¨˜å¾—æŒ‰è®šè¿½è¹¤ä¸¦å„²å­˜ç„¦ç³–æ£•è‰²éœ§...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9948dda4-f130-44e9-821c-3b75a9e573bb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4000</th>\n",
              "      <td>æ˜¯é»‘æš—çš„é™½å…‰å°‘å¥³å§ä¼Šé”é‚µç¢¼é ­</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4001</th>\n",
              "      <td>æœ¬é€±æ–°å“çœŸçš„æ˜¯é¦¬ä¸åœè¹„çš„ä¸€é€±æ˜¥è£æ–°å“è¶Šä¾†è¶Šå¤šå¯¶å¯¶å®¢äººå€‘éƒ½è²·ä¸åœèº«ç‚ºå¥³å­©å¦³èƒ½æœ‰ä¸æ¼‚äº®çš„æ¬Šåˆ©å—è®“...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4002</th>\n",
              "      <td>éœ§çœ‰ä½å®¶å·¥ä½œå®¤é ç´„å°ä¸­éœ§çœ‰</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4003</th>\n",
              "      <td>ä¸­é•·ç‰ˆæŒºæ–™è¥¿è£å¤–å¥—å…©å´å£è¢‹èˆ‡å¾®è…°èº«è¨­è¨ˆçœŸçš„å¾ˆç¾å¥¶æè‰²å¤©ç©ºè—å…±è‰²è‰å¸½å¥³å­©åœ–ç°¡ç´„åœ–ä¹Ÿæ˜¯æ™‚é«¦ç©¿æ­çš„...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4004</th>\n",
              "      <td>ç”·ç”ŸæŸ“é«®ç„¦ç³–æ£•è‰²è³ªæ„Ÿä½èª¿çš„ç„¦ç³–è‰²è®“ç”·ç”Ÿé ­é«®ä¹Ÿèƒ½æœ‰ä¸ä¸€æ¨£çš„é¸æ“‡å–œæ­¡è¨˜å¾—æŒ‰è®šè¿½è¹¤ä¸¦å„²å­˜ç„¦ç³–æ£•è‰²éœ§...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9948dda4-f130-44e9-821c-3b75a9e573bb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9948dda4-f130-44e9-821c-3b75a9e573bb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9948dda4-f130-44e9-821c-3b75a9e573bb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = train_df.text.values\n",
        "labels = train_df.label.values"
      ],
      "metadata": {
        "id": "sLTo1QCFdmD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text[455:460]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNpXn44nfVqn",
        "outputId": "fbb716ac-f05b-4695-b918-9f27f3102200"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['æ˜¯é‚£å¤©åœ¨æ©Ÿå ´è­·é€æ£®å°¼çš„äººåŸä¾†æ˜¯æ–°ç¶“ç´€äººå•Šæˆ‘é‚„ä»¥ç‚ºæ˜¯ä¿é‘£',\n",
              "       'å‰µæ¥­èµ·æ­¥ä¸¦ä¸æœƒå°è‡´å¤±æ•—æ²’æœ‰å …æŒæ‰æœƒç•¶ä½ å …æŒä¸‹å»å°±æœƒç™¼ç¾è‡ªå·±çš„èƒ½åŠ›å¾€å¾€æ¯”æƒ³åƒä¸­å¼·å¤§è»ŠèªéŒ„',\n",
              "       'å¾ç™½å¤©èŠåˆ°é»‘å¤œè¬è¬æˆ‘çš„æœ‹å‹å€‘ä¹Ÿæˆç‚ºäº†å½¼æ­¤çš„æœ‹å‹',\n",
              "       'æ¸£ç”·ç‡™æ„Ÿæƒ…ä¸Šç•¶æ¸£ç”·ç•¶ç„¶ä¸å¯ä»¥ä½†ç‡™å€‹å¸¥æ°£æ¸£ç”·ç‡™è®Šå¾—äººè¦‹äººæ„›æ˜¯å¾ˆå¯ä»¥çš„è¨­è¨ˆå¸«é ç´„å°ˆç·šåœ‹çˆ¶ç´€å¿µé¤¨è™Ÿå‡ºå£å·¦æ–œå‰æ–¹é‡‘è‰²å¤§é–€ç‡Ÿæ¥­æ™‚é–“é€±äºŒé€±å…­é€±æ—¥æ¯é€±ä¸€å…¬ä¼‘æ±å€é«®å»Šæ±å€æŸ“é«®æ±å€æŒ‘æŸ“æ±å€é«®å»Šæ¨è–¦å¤§å®‰å€é«®å»Šè—äººé€ å‹å¸«è—äººå¾¡ç”¨å°ˆæ¥­ç¾é«®æŒ‘æŸ“å°åŒ—é«®å»Šäº¬å–šç¾½è­·é«®äº¬å–šç¾½ç³»çµ±ä¿®è­·å°åŒ—å‰ªé«®å°åŒ—æŸ“é«®å°åŒ—ç‡™é«®ç‡™é«®å°åŒ—é«®å»Šæ¨è–¦',\n",
              "       'æ–°å“ä¸Šæ¶å•¦å¤©æ°£å¥½ç†±å¿«æ‰‹åˆ€æŠŠæ–°å“è²·ä¸‹ä¾†å–œæ­¡è«‹ç§è¨Šç•™è²¨ç•™è²¨ä»£è¡¨è³¼è²·å–”è¡£æœå°ºå¯¸åƒ¹æ ¼ç´°ç¯€è«‹ç§è¨Šæä¾›éƒµå¯„æœå‹™é–€å¸‚ç‡Ÿæ¥­æ™‚é–“é€±ä¸€é€±æ—¥åœ°å€æ–°åŒ—å¸‚æ¨¹æ—å€å¤§ç¾©è·¯è™Ÿä¸€æ¨“å®˜æ–¹æˆ‘å€‘çš„'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    \"bert-base-chinese\",\n",
        "    do_lower_case = True\n",
        "    )"
      ],
      "metadata": {
        "id": "Uma8Aw3AeN_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_rand_sentence():\n",
        "  '''Displays the tokens and respective IDs of a random text sample'''\n",
        "  index = random.randint(0, len(text)-1)\n",
        "  table = np.array([tokenizer.tokenize(text[index]), \n",
        "                    tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text[index]))]).T\n",
        "  print(tabulate(table,\n",
        "                 headers = ['Tokens', 'Token IDs'],\n",
        "                 tablefmt = 'fancy_grid'))\n",
        "\n",
        "print_rand_sentence()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJJZKD_pegKC",
        "outputId": "0baed4c1-e959-445c-90a2-08fc426aea65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â•’â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â••\n",
            "â”‚ Tokens   â”‚   Token IDs â”‚\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
            "â”‚ è·Ÿ       â”‚        6656 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ ä½        â”‚         872 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ åœ¨       â”‚        1762 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ ä¸€       â”‚         671 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ èµ·       â”‚        6629 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ ä»€       â”‚         784 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ éº¼       â”‚        7938 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ éƒ½       â”‚        6963 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ æ˜¯       â”‚        3221 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ æœ€       â”‚        3297 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ å¥½       â”‚        1962 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ å…©       â”‚        1060 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ é€±       â”‚        6867 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ å¹´       â”‚        2399 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ å¿«       â”‚        2571 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ æ¨‚       â”‚        3556 â”‚\n",
            "â•˜â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•›\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_id = []\n",
        "attention_masks = []\n",
        "\n",
        "def preprocessing(input_text, tokenizer):\n",
        "  '''\n",
        "  Returns <class transformers.tokenization_utils_base.BatchEncoding> with the following fields:\n",
        "    - input_ids: list of token ids\n",
        "    - token_type_ids: list of token type ids\n",
        "    - attention_mask: list of indices (0,1) specifying which tokens should considered by the model (return_attention_mask = True).\n",
        "  '''\n",
        "  return tokenizer.encode_plus(\n",
        "                        input_text,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 32,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt'\n",
        "                   )\n",
        "\n",
        "\n",
        "for sample in text:\n",
        "  encoding_dict = preprocessing(sample, tokenizer)\n",
        "  token_id.append(encoding_dict['input_ids']) \n",
        "  attention_masks.append(encoding_dict['attention_mask'])\n",
        "\n",
        "\n",
        "token_id = torch.cat(token_id, dim = 0)\n",
        "attention_masks = torch.cat(attention_masks, dim = 0)\n",
        "labels = torch.tensor(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frwHZK1PendN",
        "outputId": "f5723670-12b1-49a6-ca48-1a6b6a9cd34d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXkKR6bJgdZE",
        "outputId": "4f90607f-3d27-47fe-a4a7-9f97332add8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 101, 7526, 6257,  ...,    0,    0,    0],\n",
              "        [ 101, 5543, 1235,  ..., 4692, 4638,  102],\n",
              "        [ 101, 4373, 5455,  ...,    0,    0,    0],\n",
              "        ...,\n",
              "        [ 101, 3362, 4197,  ..., 2523, 1599,  102],\n",
              "        [ 101, 6258, 2157,  ...,    0,    0,    0],\n",
              "        [ 101, 3615, 4638,  ..., 7415, 2130,  102]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_masks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1Au9Ss7giFi",
        "outputId": "b62abf95-a72d-4e12-d84c-e23e8f9ecd3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 1, 1, 1],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [1, 1, 1,  ..., 1, 1, 1],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 1, 1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgiFXe-1gkmY",
        "outputId": "a175fb8b-142a-45a6-9c96-56d3f3945755"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 0, 1,  ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_rand_sentence_encoding():\n",
        "  '''Displays tokens, token IDs and attention mask of a random text sample'''\n",
        "  index = random.randint(0, len(text) - 1)\n",
        "  tokens = tokenizer.tokenize(tokenizer.decode(token_id[index]))\n",
        "  token_ids = [i.numpy() for i in token_id[index]]\n",
        "  attention = [i.numpy() for i in attention_masks[index]]\n",
        "\n",
        "  table = np.array([tokens, token_ids, attention]).T\n",
        "  print(tabulate(table, \n",
        "                 headers = ['Tokens', 'Token IDs', 'Attention Mask'],\n",
        "                 tablefmt = 'fancy_grid'))\n",
        "\n",
        "print_rand_sentence_encoding()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czOcTZ24gnVk",
        "outputId": "d60caf39-1ab5-41e3-d2bd-06c9a5052065"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â•’â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••\n",
            "â”‚ Tokens   â”‚   Token IDs â”‚   Attention Mask â”‚\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
            "â”‚ [CLS]    â”‚         101 â”‚                1 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ é‚£       â”‚        6929 â”‚                1 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ å¤©       â”‚        1921 â”‚                1 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ å–‡       â”‚        1589 â”‚                1 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ å­       â”‚        1375 â”‚                1 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ é–‹       â”‚        7274 â”‚                1 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ åˆ°       â”‚        1168 â”‚                1 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ æœ€       â”‚        3297 â”‚                1 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ å¤§       â”‚        1920 â”‚                1 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ éŸ³       â”‚        7509 â”‚                1 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ æ¨‚       â”‚        3556 â”‚                1 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ æ”¾       â”‚        3123 â”‚                1 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ è‘—       â”‚        5865 â”‚                1 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ é›·       â”‚        7440 â”‚                1 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ é¬¼       â”‚        7787 â”‚                1 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ ç¦¹       â”‚        4893 â”‚                1 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ å¸Œ       â”‚        2361 â”‚                1 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ åŒ       â”‚        1398 â”‚                1 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ æ¬¾       â”‚        3621 â”‚                1 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ é£†       â”‚        7598 â”‚                1 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ è»Š       â”‚        6722 â”‚                1 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ å       â”‚        1777 â”‚                1 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ è‘—       â”‚        5865 â”‚                1 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ æœ€       â”‚        3297 â”‚                1 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ å–œ       â”‚        1599 â”‚                1 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ æ­¡       â”‚        3631 â”‚                1 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ çš„       â”‚        4638 â”‚                1 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ å§¿       â”‚        2013 â”‚                1 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ å‹¢       â”‚        1248 â”‚                1 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ æ‹‰       â”‚        2861 â”‚                1 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ æ‹‰       â”‚        2861 â”‚                1 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ [SEP]    â”‚         102 â”‚                1 â”‚\n",
            "â•˜â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Training and validation"
      ],
      "metadata": {
        "id": "5bHJtKKyd99A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ’ª å¯èª¿æ•´åƒæ•¸(å¯æ¢ç´¢å„ç¨®çµ„åˆ)\n",
        "- Max length (åœ¨å‰è™•ç†çš„tokenizer.encode_plusé‚£ä¸€æ­¥å°±æœƒè¨­å®šäº†ï¼‰\n",
        "- Batch size\n",
        "- Learning rate (Adam)\n",
        "\n",
        "- Number of epochs\n",
        "- validation ratio (trainingè·Ÿvalidatingçš„è³‡æ–™æ¯”ä¾‹ï¼‰\n"
      ],
      "metadata": {
        "id": "z_EoyjHtZ7Fs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "- Batch size: 16, 32\n",
        "- Learning rate (Adam): 5e-5, 3e-5, 2e-5\n",
        "- Number of epochs: 2, 3, 4\n",
        "\n",
        "shuffle: å°åŸå§‹æ•¸æ“šé€²è¡Œéš¨æ©ŸæŠ½æ¨£ï¼Œä¿è­‰éš¨æ©Ÿæ€§ã€‚\n",
        "stratify: æƒ³è¦é”åˆ°åˆ†å±¤éš¨æ©ŸæŠ½æ¨£çš„ç›®çš„ã€‚ç‰¹åˆ¥æ˜¯åœ¨åŸå§‹æ•¸æ“šä¸­æ¨£æœ¬æ¨™ç±¤åˆ†ä½ˆä¸å‡è¡¡æ™‚éå¸¸æœ‰ç”¨ï¼Œä¸€äº›åˆ†é¡å•é¡Œå¯èƒ½æœƒåœ¨ç›®æ¨™é¡çš„åˆ†ä½ˆä¸­è¡¨ç¾å‡ºå¾ˆå¤§çš„ä¸å¹³è¡¡ï¼šä¾‹å¦‚ï¼Œè² æ¨£æœ¬å¯èƒ½æ¯”æ­£æ¨£æœ¬å¤šå¹¾å€ã€‚åœ¨é€™ç¨®æƒ…æ³ä¸‹ï¼Œå»ºè­°ä½¿ç”¨åˆ†å±¤æŠ½æ¨£\n",
        "\n",
        "'''\n",
        "val_ratio = 0.2\n",
        "batch_size = 16 \n",
        "\n",
        "# Indices of the train and validation splits stratified by labels\n",
        "train_idx, val_idx = train_test_split(\n",
        "    np.arange(len(labels)),\n",
        "    test_size = val_ratio,\n",
        "    shuffle = True,\n",
        "    stratify = labels)\n",
        "\n",
        "# Train and validation sets\n",
        "train_set = TensorDataset(token_id[train_idx], \n",
        "                          attention_masks[train_idx], \n",
        "                          labels[train_idx])\n",
        "\n",
        "val_set = TensorDataset(token_id[val_idx], \n",
        "                        attention_masks[val_idx], \n",
        "                        labels[val_idx])\n",
        "\n",
        "# Prepare DataLoader\n",
        "train_dataloader = DataLoader(\n",
        "            train_set,\n",
        "            sampler = RandomSampler(train_set),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_set,\n",
        "            sampler = SequentialSampler(val_set),\n",
        "            batch_size = batch_size\n",
        "        )"
      ],
      "metadata": {
        "id": "uJVA4YtlgubU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the BertForSequenceClassification model\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-chinese',\n",
        "    num_labels = 2,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "\n",
        "# Recommended learning rates (Adam): 5e-5, 3e-5, 2e-5. See: https://arxiv.org/pdf/1810.04805.pdf\n",
        "optimizer = torch.optim.AdamW(model.parameters(), \n",
        "                              lr = 5e-5,\n",
        "                              eps = 1e-08\n",
        "                              )\n",
        "\n",
        "# Run on GPU\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjjvC1mjicEE",
        "outputId": "77acac34-0b2d-46d4-cfb8-ac5ac2fd0abc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def b_tp(preds, labels):\n",
        "  '''Returns True Positives (TP): count of correct predictions of actual class 1'''\n",
        "  return sum([preds == labels and preds == 1 for preds, labels in zip(preds, labels)])\n",
        "\n",
        "def b_fp(preds, labels):\n",
        "  '''Returns False Positives (FP): count of wrong predictions of actual class 1'''\n",
        "  return sum([preds != labels and preds == 1 for preds, labels in zip(preds, labels)])\n",
        "\n",
        "def b_tn(preds, labels):\n",
        "  '''Returns True Negatives (TN): count of correct predictions of actual class 0'''\n",
        "  return sum([preds == labels and preds == 0 for preds, labels in zip(preds, labels)])\n",
        "\n",
        "def b_fn(preds, labels):\n",
        "  '''Returns False Negatives (FN): count of wrong predictions of actual class 0'''\n",
        "  return sum([preds != labels and preds == 0 for preds, labels in zip(preds, labels)])\n",
        "\n",
        "def b_metrics(preds, labels):\n",
        "  '''\n",
        "  Returns the following metrics:\n",
        "    - accuracy    = (TP + TN) / N\n",
        "    - precision   = TP / (TP + FP)\n",
        "    - recall      = TP / (TP + FN)\n",
        "    - specificity = TN / (TN + FP)\n",
        "  '''\n",
        "  preds = np.argmax(preds, axis = 1).flatten()\n",
        "  labels = labels.flatten()\n",
        "  tp = b_tp(preds, labels)\n",
        "  tn = b_tn(preds, labels)\n",
        "  fp = b_fp(preds, labels)\n",
        "  fn = b_fn(preds, labels)\n",
        "  b_accuracy = (tp + tn) / len(labels)\n",
        "  b_precision = tp / (tp + fp) if (tp + fp) > 0 else 'nan'\n",
        "  b_recall = tp / (tp + fn) if (tp + fn) > 0 else 'nan'\n",
        "  b_specificity = tn / (tn + fp) if (tn + fp) > 0 else 'nan'\n",
        "  return b_accuracy, b_precision, b_recall, b_specificity"
      ],
      "metadata": {
        "id": "piVdwk9IhunW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Recommended number of epochs: 2, 3, 4. See: https://arxiv.org/pdf/1810.04805.pdf\n",
        "epochs = 3\n",
        "\n",
        "for _ in trange(epochs, desc = 'Epoch'):\n",
        "    \n",
        "    # ========== Training ==========\n",
        "    \n",
        "    # Set model to training mode\n",
        "    model.train()\n",
        "    \n",
        "    # Tracking variables\n",
        "    tr_loss = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass\n",
        "        train_output = model(b_input_ids, \n",
        "                             token_type_ids = None, \n",
        "                             attention_mask = b_input_mask, \n",
        "                             labels = b_labels)\n",
        "        # Backward pass\n",
        "        train_output.loss.backward()\n",
        "        optimizer.step()\n",
        "        # Update tracking variables\n",
        "        tr_loss += train_output.loss.item()\n",
        "        nb_tr_examples += b_input_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "\n",
        "    # ========== Validation ==========\n",
        "\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    val_accuracy = []\n",
        "    val_precision = []\n",
        "    val_recall = []\n",
        "    val_specificity = []\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        with torch.no_grad():\n",
        "          # Forward pass\n",
        "          eval_output = model(b_input_ids, \n",
        "                              token_type_ids = None, \n",
        "                              attention_mask = b_input_mask)\n",
        "        logits = eval_output.logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        # Calculate validation metrics\n",
        "        b_accuracy, b_precision, b_recall, b_specificity = b_metrics(logits, label_ids)\n",
        "        val_accuracy.append(b_accuracy)\n",
        "        # Update precision only when (tp + fp) !=0; ignore nan\n",
        "        if b_precision != 'nan': val_precision.append(b_precision)\n",
        "        # Update recall only when (tp + fn) !=0; ignore nan\n",
        "        if b_recall != 'nan': val_recall.append(b_recall)\n",
        "        # Update specificity only when (tn + fp) !=0; ignore nan\n",
        "        if b_specificity != 'nan': val_specificity.append(b_specificity)\n",
        "\n",
        "    print('\\n\\t - Train loss: {:.4f}'.format(tr_loss / nb_tr_steps))\n",
        "    print('\\t - Validation Accuracy: {:.4f}'.format(sum(val_accuracy)/len(val_accuracy)))\n",
        "    print('\\t - Validation Precision: {:.4f}'.format(sum(val_precision)/len(val_precision)) if len(val_precision)>0 else '\\t - Validation Precision: NaN')\n",
        "    print('\\t - Validation Recall: {:.4f}'.format(sum(val_recall)/len(val_recall)) if len(val_recall)>0 else '\\t - Validation Recall: NaN')\n",
        "    print('\\t - Validation Specificity: {:.4f}\\n'.format(sum(val_specificity)/len(val_specificity)) if len(val_specificity)>0 else '\\t - Validation Specificity: NaN')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfnLTp4Aiv6F",
        "outputId": "d3be82d3-2cb3-473a-8cbd-b973dc965439"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:25<00:50, 25.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t - Train loss: 0.4099\n",
            "\t - Validation Accuracy: 0.8688\n",
            "\t - Validation Precision: 0.9139\n",
            "\t - Validation Recall: 0.8013\n",
            "\t - Validation Specificity: 0.9321\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:50<00:25, 25.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t - Train loss: 0.2723\n",
            "\t - Validation Accuracy: 0.8213\n",
            "\t - Validation Precision: 0.7653\n",
            "\t - Validation Recall: 0.8994\n",
            "\t - Validation Specificity: 0.7407\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [01:15<00:00, 25.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t - Train loss: 0.1778\n",
            "\t - Validation Accuracy: 0.8588\n",
            "\t - Validation Precision: 0.8458\n",
            "\t - Validation Recall: 0.8580\n",
            "\t - Validation Specificity: 0.8528\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#with open('/content/gdrive/MyDrive/NTU GIL/CLLT ta/HW9_fine-tuned BERT/model.pkl', 'wb')as f:\n",
        " #   pickle.dump(model, f)"
      ],
      "metadata": {
        "id": "LMoblKWqq4et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting\n",
        "\n",
        "â­ è¨˜å¾—ä½¿ç”¨test_df!"
      ],
      "metadata": {
        "id": "e_mfmCCqdpBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing data prediction\n",
        "\n",
        "test_txt = test_df.text.values\n",
        "test_lbl = test_df.label.values\n",
        "\n",
        "# We need Token IDs and Attention Mask for inference on the new sentence\n",
        "test_ids = []\n",
        "test_attention_mask = []\n",
        "\n",
        "# Apply the tokenizer\n",
        "for sample in test_txt:\n",
        "  encoding_dict = preprocessing(sample, tokenizer)\n",
        "  test_ids.append(encoding_dict['input_ids']) \n",
        "  test_attention_mask.append(encoding_dict['attention_mask'])\n",
        "\n",
        "\n",
        "test_ids = torch.cat(test_ids, dim = 0)\n",
        "test_attention_mask = torch.cat(test_attention_mask, dim = 0)\n",
        "test_lbl = torch.tensor(test_lbl)\n",
        "\n",
        "print(test_ids[0])\n",
        "print(test_attention_mask[0])\n",
        "print(test_lbl[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5HAcJjDkPZT",
        "outputId": "3900ef0d-e7ba-410a-aee3-3f41448a85c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 101, 3221, 7946, 3266, 4638, 7382, 1045, 2208, 1957, 1416,  823, 6888,\n",
            "        6939, 4826, 7531,  102,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "tensor(0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = TensorDataset(test_ids, test_attention_mask)\n",
        "test_dataloader = DataLoader(\n",
        "            test_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(test_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "metadata": {
        "id": "itFVmid4nJLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "\n",
        "for batch in test_dataloader:\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        with torch.no_grad():        \n",
        "            output= model(b_input_ids, \n",
        "                          token_type_ids=None, \n",
        "                          attention_mask=b_input_mask)\n",
        "            logits = output.logits\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "\n",
        "            pred_flat = np.argmax(logits, axis=1).flatten()\n",
        "            predictions.extend(list(pred_flat))\n",
        "\n",
        "test_df['prediction'] = predictions\n",
        "test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "GFcSidtknZrM",
        "outputId": "56391be3-48da-447a-a08a-384303dc7ff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-61-fad07656194b>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_df['prediction'] = predictions\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  label  prediction\n",
              "4000                                     æ˜¯é»‘æš—çš„é™½å…‰å°‘å¥³å§ä¼Šé”é‚µç¢¼é ­      0           0\n",
              "4001  æœ¬é€±æ–°å“çœŸçš„æ˜¯é¦¬ä¸åœè¹„çš„ä¸€é€±æ˜¥è£æ–°å“è¶Šä¾†è¶Šå¤šå¯¶å¯¶å®¢äººå€‘éƒ½è²·ä¸åœèº«ç‚ºå¥³å­©å¦³èƒ½æœ‰ä¸æ¼‚äº®çš„æ¬Šåˆ©å—è®“...      1           1\n",
              "4002                                      éœ§çœ‰ä½å®¶å·¥ä½œå®¤é ç´„å°ä¸­éœ§çœ‰      1           1\n",
              "4003  ä¸­é•·ç‰ˆæŒºæ–™è¥¿è£å¤–å¥—å…©å´å£è¢‹èˆ‡å¾®è…°èº«è¨­è¨ˆçœŸçš„å¾ˆç¾å¥¶æè‰²å¤©ç©ºè—å…±è‰²è‰å¸½å¥³å­©åœ–ç°¡ç´„åœ–ä¹Ÿæ˜¯æ™‚é«¦ç©¿æ­çš„...      1           1\n",
              "4004  ç”·ç”ŸæŸ“é«®ç„¦ç³–æ£•è‰²è³ªæ„Ÿä½èª¿çš„ç„¦ç³–è‰²è®“ç”·ç”Ÿé ­é«®ä¹Ÿèƒ½æœ‰ä¸ä¸€æ¨£çš„é¸æ“‡å–œæ­¡è¨˜å¾—æŒ‰è®šè¿½è¹¤ä¸¦å„²å­˜ç„¦ç³–æ£•è‰²éœ§...      1           1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7c6cabdf-0f3b-4569-b9bb-073f7615b031\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4000</th>\n",
              "      <td>æ˜¯é»‘æš—çš„é™½å…‰å°‘å¥³å§ä¼Šé”é‚µç¢¼é ­</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4001</th>\n",
              "      <td>æœ¬é€±æ–°å“çœŸçš„æ˜¯é¦¬ä¸åœè¹„çš„ä¸€é€±æ˜¥è£æ–°å“è¶Šä¾†è¶Šå¤šå¯¶å¯¶å®¢äººå€‘éƒ½è²·ä¸åœèº«ç‚ºå¥³å­©å¦³èƒ½æœ‰ä¸æ¼‚äº®çš„æ¬Šåˆ©å—è®“...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4002</th>\n",
              "      <td>éœ§çœ‰ä½å®¶å·¥ä½œå®¤é ç´„å°ä¸­éœ§çœ‰</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4003</th>\n",
              "      <td>ä¸­é•·ç‰ˆæŒºæ–™è¥¿è£å¤–å¥—å…©å´å£è¢‹èˆ‡å¾®è…°èº«è¨­è¨ˆçœŸçš„å¾ˆç¾å¥¶æè‰²å¤©ç©ºè—å…±è‰²è‰å¸½å¥³å­©åœ–ç°¡ç´„åœ–ä¹Ÿæ˜¯æ™‚é«¦ç©¿æ­çš„...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4004</th>\n",
              "      <td>ç”·ç”ŸæŸ“é«®ç„¦ç³–æ£•è‰²è³ªæ„Ÿä½èª¿çš„ç„¦ç³–è‰²è®“ç”·ç”Ÿé ­é«®ä¹Ÿèƒ½æœ‰ä¸ä¸€æ¨£çš„é¸æ“‡å–œæ­¡è¨˜å¾—æŒ‰è®šè¿½è¹¤ä¸¦å„²å­˜ç„¦ç³–æ£•è‰²éœ§...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c6cabdf-0f3b-4569-b9bb-073f7615b031')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7c6cabdf-0f3b-4569-b9bb-073f7615b031 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7c6cabdf-0f3b-4569-b9bb-073f7615b031');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate validation metrics\n",
        "preds = test_df['prediction']\n",
        "labels = test_df['label']\n",
        "\n",
        "b_tp = sum([preds == labels and preds == 1 for preds, labels in zip(preds, labels)])\n",
        "b_fp = sum([preds != labels and preds == 1 for preds, labels in zip(preds, labels)]) #false positive\n",
        "b_tn = sum([preds == labels and preds == 0 for preds, labels in zip(preds, labels)]) #true negative\n",
        "b_fn =  sum([preds != labels and preds == 0 for preds, labels in zip(preds, labels)])\n",
        "\n",
        "'''\n",
        "  Returns the following metrics:\n",
        "    - accuracy    = (TP + TN) / N\n",
        "    - precision   = TP / (TP + FP)\n",
        "    - recall      = TP / (TP + FN)\n",
        "    - specificity = TN / (TN + FP)\n",
        "'''\n",
        "\n",
        "test_accuracy = (b_tp + b_tn) / len(labels)\n",
        "test_precision = b_tp / (b_tp + b_fp) if (b_tp + b_fp) > 0 else 'nan'\n",
        "test_recall = b_tp / (b_tp + b_fn) if (b_tp + b_fn) > 0 else 'nan'\n",
        "test_specificity = b_tn / (b_tn + b_fp) if (b_tn + b_fp) > 0 else 'nan'\n",
        "\n",
        "print(f'test_accuracy: {test_accuracy}')\n",
        "print(f'test_precision: {test_precision}')\n",
        "print(f'test_recall: {test_recall}')\n",
        "print(f'test_specificity: {test_specificity}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v___pIqBrwVx",
        "outputId": "10462d13-cfb2-4c62-8a19-e14bd7ce916a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_accuracy: 0.863\n",
            "test_precision: 0.8532289628180039\n",
            "test_recall: 0.8755020080321285\n",
            "test_specificity: 0.850597609561753\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ErPPSbnZmMc4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}