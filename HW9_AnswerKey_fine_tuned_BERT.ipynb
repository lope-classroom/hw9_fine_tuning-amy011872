{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# HW9 - Fine-tuning BERT!\n",
        "\n",
        "> 任務: 以BERT為基礎，fine-tune 出一個可以判斷文章「是否為廣告」的模型（label \"1\" 為廣告、\"0\"為非廣告）\n",
        "\n",
        "> 計分方式：\n",
        "1. Preprocessing (20%)\n",
        "2. Training and validating (30%)\n",
        "3. Predicting (20%)\n",
        "4. **有做兩組以上的嘗試** （10%)（需在Markdown寫出你嘗試的參數組合及結果）\n",
        "5. 取Accuracy最高的結果：(Acc - 0.8)x100\n",
        "   例如你最好的model正確率有0.88，那你就會再加上(0.88-0.8)x100=8分！"
      ],
      "metadata": {
        "id": "bUhZz0QTurYo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "給定train_df和test_df兩份資料，其中train_df為4000筆未經前處理的資料，test_df為1000筆清理乾淨的資料。"
      ],
      "metadata": {
        "id": "jpuZFtj1wEEN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Preprocessing steps with BERT \n",
        "\n",
        "💪 pretrained model請使用\"bert-base-chinese\" & BertForSequenceClassification (設定如下所示）\n",
        "\n",
        "💪 \n",
        "前處理步驟\n",
        "\n",
        "1. 加入special tokens:\n",
        "  - [CLS]: 每個句子的開頭 (ID 101)\n",
        "  - [SEP]: 每個句子的結尾 (ID 102)\n",
        "2. 每個句子長度相等:\n",
        "  - 設定maximum sequence length，最多可到 512 tokens\n",
        "  - Padding([PAD]) ：不足max length的句子以 ID 0補滿\n",
        "  - Truncated: 太長的句子就切到max length\n",
        "3. Attention mask:\n",
        "  - List of 0/1 indicating whether the model should consider the tokens or not when learning their contextual representation. (special tokens也是1，只有[PAD] tokens為 0）\n",
        "\n",
        "使用``tokenizer.encode_plus``這個function，得到結果會包含:\n",
        "\n",
        "- input_ids: list of token IDs.\n",
        "- attention_mask: list of 0/1 indicating which tokens should be considered by the model (return_attention_mask = True).\n"
      ],
      "metadata": {
        "id": "vcZru24fWmlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "zKAPv3ded9R0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from tabulate import tabulate\n",
        "from tqdm import trange\n",
        "import random"
      ],
      "metadata": {
        "id": "NAY6Vre3d-m2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "b975e9f3-0fcf-425b-fe11-d482aae61104",
        "id": "f2eGv59ofmm_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  label\n",
              "0  V領設計能夠修飾臉型😍\\n減齡泡泡袖洋裝😉\\n👉https://lihi1.com/JDym...      1\n",
              "1  【20210303】\\n能勇敢追夢的人\\n身上都閃著和煦的光芒\\n也是好生羨慕！\\n-\\n敬...      0\n",
              "2                             玉 耳環\\n#耳環 #玉 #earrings      1\n",
              "3  【美國瘋潮WWE Taiwan】\\n不管是WWE Elite還是AEW Unrivaled系...      1\n",
              "4  🌈\\n尋晚的post 一po已經被秒殺好多件的Vintage sports windbrea...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f54a574d-48f5-4196-a9c4-081f6cb9b36b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>V領設計能夠修飾臉型😍\\n減齡泡泡袖洋裝😉\\n👉https://lihi1.com/JDym...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>【20210303】\\n能勇敢追夢的人\\n身上都閃著和煦的光芒\\n也是好生羨慕！\\n-\\n敬...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>玉 耳環\\n#耳環 #玉 #earrings</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>【美國瘋潮WWE Taiwan】\\n不管是WWE Elite還是AEW Unrivaled系...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>🌈\\n尋晚的post 一po已經被秒殺好多件的Vintage sports windbrea...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f54a574d-48f5-4196-a9c4-081f6cb9b36b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f54a574d-48f5-4196-a9c4-081f6cb9b36b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f54a574d-48f5-4196-a9c4-081f6cb9b36b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "d561432f-de35-4dc5-ea78-f79384671f99",
        "id": "JHof_XYFfonH"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  label\n",
              "4000                                     是黑暗的陽光少女吧伊達邵碼頭      0\n",
              "4001  本週新品真的是馬不停蹄的一週春裝新品越來越多寶寶客人們都買不停身為女孩妳能有不漂亮的權利嗎讓...      1\n",
              "4002                                      霧眉住家工作室預約台中霧眉      1\n",
              "4003  中長版挺料西裝外套兩側口袋與微腰身設計真的很美奶杏色天空藍共色草帽女孩圖簡約圖也是時髦穿搭的...      1\n",
              "4004  男生染髮焦糖棕色質感低調的焦糖色讓男生頭髮也能有不一樣的選擇喜歡記得按讚追蹤並儲存焦糖棕色霧...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9948dda4-f130-44e9-821c-3b75a9e573bb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4000</th>\n",
              "      <td>是黑暗的陽光少女吧伊達邵碼頭</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4001</th>\n",
              "      <td>本週新品真的是馬不停蹄的一週春裝新品越來越多寶寶客人們都買不停身為女孩妳能有不漂亮的權利嗎讓...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4002</th>\n",
              "      <td>霧眉住家工作室預約台中霧眉</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4003</th>\n",
              "      <td>中長版挺料西裝外套兩側口袋與微腰身設計真的很美奶杏色天空藍共色草帽女孩圖簡約圖也是時髦穿搭的...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4004</th>\n",
              "      <td>男生染髮焦糖棕色質感低調的焦糖色讓男生頭髮也能有不一樣的選擇喜歡記得按讚追蹤並儲存焦糖棕色霧...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9948dda4-f130-44e9-821c-3b75a9e573bb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9948dda4-f130-44e9-821c-3b75a9e573bb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9948dda4-f130-44e9-821c-3b75a9e573bb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = train_df.text.values\n",
        "labels = train_df.label.values"
      ],
      "metadata": {
        "id": "sLTo1QCFdmD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text[455:460]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNpXn44nfVqn",
        "outputId": "fbb716ac-f05b-4695-b918-9f27f3102200"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['是那天在機場護送森尼的人原來是新經紀人啊我還以為是保鑣',\n",
              "       '創業起步並不會導致失敗沒有堅持才會當你堅持下去就會發現自己的能力往往比想像中強大車語錄',\n",
              "       '從白天聊到黑夜謝謝我的朋友們也成為了彼此的朋友',\n",
              "       '渣男燙感情上當渣男當然不可以但燙個帥氣渣男燙變得人見人愛是很可以的設計師預約專線國父紀念館號出口左斜前方金色大門營業時間週二週六週日每週一公休東區髮廊東區染髮東區挑染東區髮廊推薦大安區髮廊藝人造型師藝人御用專業美髮挑染台北髮廊京喚羽護髮京喚羽系統修護台北剪髮台北染髮台北燙髮燙髮台北髮廊推薦',\n",
              "       '新品上架啦天氣好熱快手刀把新品買下來喜歡請私訊留貨留貨代表購買喔衣服尺寸價格細節請私訊提供郵寄服務門市營業時間週一週日地址新北市樹林區大義路號一樓官方我們的'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    \"bert-base-chinese\",\n",
        "    do_lower_case = True\n",
        "    )"
      ],
      "metadata": {
        "id": "Uma8Aw3AeN_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_rand_sentence():\n",
        "  '''Displays the tokens and respective IDs of a random text sample'''\n",
        "  index = random.randint(0, len(text)-1)\n",
        "  table = np.array([tokenizer.tokenize(text[index]), \n",
        "                    tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text[index]))]).T\n",
        "  print(tabulate(table,\n",
        "                 headers = ['Tokens', 'Token IDs'],\n",
        "                 tablefmt = 'fancy_grid'))\n",
        "\n",
        "print_rand_sentence()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJJZKD_pegKC",
        "outputId": "0baed4c1-e959-445c-90a2-08fc426aea65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "╒══════════╤═════════════╕\n",
            "│ Tokens   │   Token IDs │\n",
            "╞══════════╪═════════════╡\n",
            "│ 跟       │        6656 │\n",
            "├──────────┼─────────────┤\n",
            "│ 你       │         872 │\n",
            "├──────────┼─────────────┤\n",
            "│ 在       │        1762 │\n",
            "├──────────┼─────────────┤\n",
            "│ 一       │         671 │\n",
            "├──────────┼─────────────┤\n",
            "│ 起       │        6629 │\n",
            "├──────────┼─────────────┤\n",
            "│ 什       │         784 │\n",
            "├──────────┼─────────────┤\n",
            "│ 麼       │        7938 │\n",
            "├──────────┼─────────────┤\n",
            "│ 都       │        6963 │\n",
            "├──────────┼─────────────┤\n",
            "│ 是       │        3221 │\n",
            "├──────────┼─────────────┤\n",
            "│ 最       │        3297 │\n",
            "├──────────┼─────────────┤\n",
            "│ 好       │        1962 │\n",
            "├──────────┼─────────────┤\n",
            "│ 兩       │        1060 │\n",
            "├──────────┼─────────────┤\n",
            "│ 週       │        6867 │\n",
            "├──────────┼─────────────┤\n",
            "│ 年       │        2399 │\n",
            "├──────────┼─────────────┤\n",
            "│ 快       │        2571 │\n",
            "├──────────┼─────────────┤\n",
            "│ 樂       │        3556 │\n",
            "╘══════════╧═════════════╛\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_id = []\n",
        "attention_masks = []\n",
        "\n",
        "def preprocessing(input_text, tokenizer):\n",
        "  '''\n",
        "  Returns <class transformers.tokenization_utils_base.BatchEncoding> with the following fields:\n",
        "    - input_ids: list of token ids\n",
        "    - token_type_ids: list of token type ids\n",
        "    - attention_mask: list of indices (0,1) specifying which tokens should considered by the model (return_attention_mask = True).\n",
        "  '''\n",
        "  return tokenizer.encode_plus(\n",
        "                        input_text,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 32,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt'\n",
        "                   )\n",
        "\n",
        "\n",
        "for sample in text:\n",
        "  encoding_dict = preprocessing(sample, tokenizer)\n",
        "  token_id.append(encoding_dict['input_ids']) \n",
        "  attention_masks.append(encoding_dict['attention_mask'])\n",
        "\n",
        "\n",
        "token_id = torch.cat(token_id, dim = 0)\n",
        "attention_masks = torch.cat(attention_masks, dim = 0)\n",
        "labels = torch.tensor(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frwHZK1PendN",
        "outputId": "f5723670-12b1-49a6-ca48-1a6b6a9cd34d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXkKR6bJgdZE",
        "outputId": "4f90607f-3d27-47fe-a4a7-9f97332add8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 101, 7526, 6257,  ...,    0,    0,    0],\n",
              "        [ 101, 5543, 1235,  ..., 4692, 4638,  102],\n",
              "        [ 101, 4373, 5455,  ...,    0,    0,    0],\n",
              "        ...,\n",
              "        [ 101, 3362, 4197,  ..., 2523, 1599,  102],\n",
              "        [ 101, 6258, 2157,  ...,    0,    0,    0],\n",
              "        [ 101, 3615, 4638,  ..., 7415, 2130,  102]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_masks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1Au9Ss7giFi",
        "outputId": "b62abf95-a72d-4e12-d84c-e23e8f9ecd3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 1, 1, 1],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [1, 1, 1,  ..., 1, 1, 1],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 1, 1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgiFXe-1gkmY",
        "outputId": "a175fb8b-142a-45a6-9c96-56d3f3945755"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 0, 1,  ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_rand_sentence_encoding():\n",
        "  '''Displays tokens, token IDs and attention mask of a random text sample'''\n",
        "  index = random.randint(0, len(text) - 1)\n",
        "  tokens = tokenizer.tokenize(tokenizer.decode(token_id[index]))\n",
        "  token_ids = [i.numpy() for i in token_id[index]]\n",
        "  attention = [i.numpy() for i in attention_masks[index]]\n",
        "\n",
        "  table = np.array([tokens, token_ids, attention]).T\n",
        "  print(tabulate(table, \n",
        "                 headers = ['Tokens', 'Token IDs', 'Attention Mask'],\n",
        "                 tablefmt = 'fancy_grid'))\n",
        "\n",
        "print_rand_sentence_encoding()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czOcTZ24gnVk",
        "outputId": "d60caf39-1ab5-41e3-d2bd-06c9a5052065"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "╒══════════╤═════════════╤══════════════════╕\n",
            "│ Tokens   │   Token IDs │   Attention Mask │\n",
            "╞══════════╪═════════════╪══════════════════╡\n",
            "│ [CLS]    │         101 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ 那       │        6929 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ 天       │        1921 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ 喇       │        1589 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ 叭       │        1375 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ 開       │        7274 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ 到       │        1168 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ 最       │        3297 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ 大       │        1920 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ 音       │        7509 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ 樂       │        3556 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ 放       │        3123 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ 著       │        5865 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ 雷       │        7440 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ 鬼       │        7787 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ 禹       │        4893 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ 希       │        2361 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ 同       │        1398 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ 款       │        3621 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ 飆       │        7598 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ 車       │        6722 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ 坐       │        1777 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ 著       │        5865 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ 最       │        3297 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ 喜       │        1599 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ 歡       │        3631 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ 的       │        4638 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ 姿       │        2013 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ 勢       │        1248 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ 拉       │        2861 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ 拉       │        2861 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ [SEP]    │         102 │                1 │\n",
            "╘══════════╧═════════════╧══════════════════╛\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Training and validation"
      ],
      "metadata": {
        "id": "5bHJtKKyd99A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "💪 可調整參數(可探索各種組合)\n",
        "- Max length (在前處理的tokenizer.encode_plus那一步就會設定了）\n",
        "- Batch size\n",
        "- Learning rate (Adam)\n",
        "\n",
        "- Number of epochs\n",
        "- validation ratio (training跟validating的資料比例）\n"
      ],
      "metadata": {
        "id": "z_EoyjHtZ7Fs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "- Batch size: 16, 32\n",
        "- Learning rate (Adam): 5e-5, 3e-5, 2e-5\n",
        "- Number of epochs: 2, 3, 4\n",
        "\n",
        "shuffle: 對原始數據進行隨機抽樣，保證隨機性。\n",
        "stratify: 想要達到分層隨機抽樣的目的。特別是在原始數據中樣本標籤分佈不均衡時非常有用，一些分類問題可能會在目標類的分佈中表現出很大的不平衡：例如，負樣本可能比正樣本多幾倍。在這種情況下，建議使用分層抽樣\n",
        "\n",
        "'''\n",
        "val_ratio = 0.2\n",
        "batch_size = 16 \n",
        "\n",
        "# Indices of the train and validation splits stratified by labels\n",
        "train_idx, val_idx = train_test_split(\n",
        "    np.arange(len(labels)),\n",
        "    test_size = val_ratio,\n",
        "    shuffle = True,\n",
        "    stratify = labels)\n",
        "\n",
        "# Train and validation sets\n",
        "train_set = TensorDataset(token_id[train_idx], \n",
        "                          attention_masks[train_idx], \n",
        "                          labels[train_idx])\n",
        "\n",
        "val_set = TensorDataset(token_id[val_idx], \n",
        "                        attention_masks[val_idx], \n",
        "                        labels[val_idx])\n",
        "\n",
        "# Prepare DataLoader\n",
        "train_dataloader = DataLoader(\n",
        "            train_set,\n",
        "            sampler = RandomSampler(train_set),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_set,\n",
        "            sampler = SequentialSampler(val_set),\n",
        "            batch_size = batch_size\n",
        "        )"
      ],
      "metadata": {
        "id": "uJVA4YtlgubU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the BertForSequenceClassification model\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-chinese',\n",
        "    num_labels = 2,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "\n",
        "# Recommended learning rates (Adam): 5e-5, 3e-5, 2e-5. See: https://arxiv.org/pdf/1810.04805.pdf\n",
        "optimizer = torch.optim.AdamW(model.parameters(), \n",
        "                              lr = 5e-5,\n",
        "                              eps = 1e-08\n",
        "                              )\n",
        "\n",
        "# Run on GPU\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjjvC1mjicEE",
        "outputId": "77acac34-0b2d-46d4-cfb8-ac5ac2fd0abc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def b_tp(preds, labels):\n",
        "  '''Returns True Positives (TP): count of correct predictions of actual class 1'''\n",
        "  return sum([preds == labels and preds == 1 for preds, labels in zip(preds, labels)])\n",
        "\n",
        "def b_fp(preds, labels):\n",
        "  '''Returns False Positives (FP): count of wrong predictions of actual class 1'''\n",
        "  return sum([preds != labels and preds == 1 for preds, labels in zip(preds, labels)])\n",
        "\n",
        "def b_tn(preds, labels):\n",
        "  '''Returns True Negatives (TN): count of correct predictions of actual class 0'''\n",
        "  return sum([preds == labels and preds == 0 for preds, labels in zip(preds, labels)])\n",
        "\n",
        "def b_fn(preds, labels):\n",
        "  '''Returns False Negatives (FN): count of wrong predictions of actual class 0'''\n",
        "  return sum([preds != labels and preds == 0 for preds, labels in zip(preds, labels)])\n",
        "\n",
        "def b_metrics(preds, labels):\n",
        "  '''\n",
        "  Returns the following metrics:\n",
        "    - accuracy    = (TP + TN) / N\n",
        "    - precision   = TP / (TP + FP)\n",
        "    - recall      = TP / (TP + FN)\n",
        "    - specificity = TN / (TN + FP)\n",
        "  '''\n",
        "  preds = np.argmax(preds, axis = 1).flatten()\n",
        "  labels = labels.flatten()\n",
        "  tp = b_tp(preds, labels)\n",
        "  tn = b_tn(preds, labels)\n",
        "  fp = b_fp(preds, labels)\n",
        "  fn = b_fn(preds, labels)\n",
        "  b_accuracy = (tp + tn) / len(labels)\n",
        "  b_precision = tp / (tp + fp) if (tp + fp) > 0 else 'nan'\n",
        "  b_recall = tp / (tp + fn) if (tp + fn) > 0 else 'nan'\n",
        "  b_specificity = tn / (tn + fp) if (tn + fp) > 0 else 'nan'\n",
        "  return b_accuracy, b_precision, b_recall, b_specificity"
      ],
      "metadata": {
        "id": "piVdwk9IhunW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Recommended number of epochs: 2, 3, 4. See: https://arxiv.org/pdf/1810.04805.pdf\n",
        "epochs = 3\n",
        "\n",
        "for _ in trange(epochs, desc = 'Epoch'):\n",
        "    \n",
        "    # ========== Training ==========\n",
        "    \n",
        "    # Set model to training mode\n",
        "    model.train()\n",
        "    \n",
        "    # Tracking variables\n",
        "    tr_loss = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass\n",
        "        train_output = model(b_input_ids, \n",
        "                             token_type_ids = None, \n",
        "                             attention_mask = b_input_mask, \n",
        "                             labels = b_labels)\n",
        "        # Backward pass\n",
        "        train_output.loss.backward()\n",
        "        optimizer.step()\n",
        "        # Update tracking variables\n",
        "        tr_loss += train_output.loss.item()\n",
        "        nb_tr_examples += b_input_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "\n",
        "    # ========== Validation ==========\n",
        "\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    val_accuracy = []\n",
        "    val_precision = []\n",
        "    val_recall = []\n",
        "    val_specificity = []\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        with torch.no_grad():\n",
        "          # Forward pass\n",
        "          eval_output = model(b_input_ids, \n",
        "                              token_type_ids = None, \n",
        "                              attention_mask = b_input_mask)\n",
        "        logits = eval_output.logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        # Calculate validation metrics\n",
        "        b_accuracy, b_precision, b_recall, b_specificity = b_metrics(logits, label_ids)\n",
        "        val_accuracy.append(b_accuracy)\n",
        "        # Update precision only when (tp + fp) !=0; ignore nan\n",
        "        if b_precision != 'nan': val_precision.append(b_precision)\n",
        "        # Update recall only when (tp + fn) !=0; ignore nan\n",
        "        if b_recall != 'nan': val_recall.append(b_recall)\n",
        "        # Update specificity only when (tn + fp) !=0; ignore nan\n",
        "        if b_specificity != 'nan': val_specificity.append(b_specificity)\n",
        "\n",
        "    print('\\n\\t - Train loss: {:.4f}'.format(tr_loss / nb_tr_steps))\n",
        "    print('\\t - Validation Accuracy: {:.4f}'.format(sum(val_accuracy)/len(val_accuracy)))\n",
        "    print('\\t - Validation Precision: {:.4f}'.format(sum(val_precision)/len(val_precision)) if len(val_precision)>0 else '\\t - Validation Precision: NaN')\n",
        "    print('\\t - Validation Recall: {:.4f}'.format(sum(val_recall)/len(val_recall)) if len(val_recall)>0 else '\\t - Validation Recall: NaN')\n",
        "    print('\\t - Validation Specificity: {:.4f}\\n'.format(sum(val_specificity)/len(val_specificity)) if len(val_specificity)>0 else '\\t - Validation Specificity: NaN')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfnLTp4Aiv6F",
        "outputId": "d3be82d3-2cb3-473a-8cbd-b973dc965439"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:  33%|███▎      | 1/3 [00:25<00:50, 25.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t - Train loss: 0.4099\n",
            "\t - Validation Accuracy: 0.8688\n",
            "\t - Validation Precision: 0.9139\n",
            "\t - Validation Recall: 0.8013\n",
            "\t - Validation Specificity: 0.9321\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  67%|██████▋   | 2/3 [00:50<00:25, 25.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t - Train loss: 0.2723\n",
            "\t - Validation Accuracy: 0.8213\n",
            "\t - Validation Precision: 0.7653\n",
            "\t - Validation Recall: 0.8994\n",
            "\t - Validation Specificity: 0.7407\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 100%|██████████| 3/3 [01:15<00:00, 25.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t - Train loss: 0.1778\n",
            "\t - Validation Accuracy: 0.8588\n",
            "\t - Validation Precision: 0.8458\n",
            "\t - Validation Recall: 0.8580\n",
            "\t - Validation Specificity: 0.8528\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#with open('/content/gdrive/MyDrive/NTU GIL/CLLT ta/HW9_fine-tuned BERT/model.pkl', 'wb')as f:\n",
        " #   pickle.dump(model, f)"
      ],
      "metadata": {
        "id": "LMoblKWqq4et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting\n",
        "\n",
        "⭐ 記得使用test_df!"
      ],
      "metadata": {
        "id": "e_mfmCCqdpBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing data prediction\n",
        "\n",
        "test_txt = test_df.text.values\n",
        "test_lbl = test_df.label.values\n",
        "\n",
        "# We need Token IDs and Attention Mask for inference on the new sentence\n",
        "test_ids = []\n",
        "test_attention_mask = []\n",
        "\n",
        "# Apply the tokenizer\n",
        "for sample in test_txt:\n",
        "  encoding_dict = preprocessing(sample, tokenizer)\n",
        "  test_ids.append(encoding_dict['input_ids']) \n",
        "  test_attention_mask.append(encoding_dict['attention_mask'])\n",
        "\n",
        "\n",
        "test_ids = torch.cat(test_ids, dim = 0)\n",
        "test_attention_mask = torch.cat(test_attention_mask, dim = 0)\n",
        "test_lbl = torch.tensor(test_lbl)\n",
        "\n",
        "print(test_ids[0])\n",
        "print(test_attention_mask[0])\n",
        "print(test_lbl[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5HAcJjDkPZT",
        "outputId": "3900ef0d-e7ba-410a-aee3-3f41448a85c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 101, 3221, 7946, 3266, 4638, 7382, 1045, 2208, 1957, 1416,  823, 6888,\n",
            "        6939, 4826, 7531,  102,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "tensor(0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = TensorDataset(test_ids, test_attention_mask)\n",
        "test_dataloader = DataLoader(\n",
        "            test_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(test_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "metadata": {
        "id": "itFVmid4nJLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "\n",
        "for batch in test_dataloader:\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        with torch.no_grad():        \n",
        "            output= model(b_input_ids, \n",
        "                          token_type_ids=None, \n",
        "                          attention_mask=b_input_mask)\n",
        "            logits = output.logits\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "\n",
        "            pred_flat = np.argmax(logits, axis=1).flatten()\n",
        "            predictions.extend(list(pred_flat))\n",
        "\n",
        "test_df['prediction'] = predictions\n",
        "test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "GFcSidtknZrM",
        "outputId": "56391be3-48da-447a-a08a-384303dc7ff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-61-fad07656194b>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_df['prediction'] = predictions\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  label  prediction\n",
              "4000                                     是黑暗的陽光少女吧伊達邵碼頭      0           0\n",
              "4001  本週新品真的是馬不停蹄的一週春裝新品越來越多寶寶客人們都買不停身為女孩妳能有不漂亮的權利嗎讓...      1           1\n",
              "4002                                      霧眉住家工作室預約台中霧眉      1           1\n",
              "4003  中長版挺料西裝外套兩側口袋與微腰身設計真的很美奶杏色天空藍共色草帽女孩圖簡約圖也是時髦穿搭的...      1           1\n",
              "4004  男生染髮焦糖棕色質感低調的焦糖色讓男生頭髮也能有不一樣的選擇喜歡記得按讚追蹤並儲存焦糖棕色霧...      1           1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7c6cabdf-0f3b-4569-b9bb-073f7615b031\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4000</th>\n",
              "      <td>是黑暗的陽光少女吧伊達邵碼頭</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4001</th>\n",
              "      <td>本週新品真的是馬不停蹄的一週春裝新品越來越多寶寶客人們都買不停身為女孩妳能有不漂亮的權利嗎讓...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4002</th>\n",
              "      <td>霧眉住家工作室預約台中霧眉</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4003</th>\n",
              "      <td>中長版挺料西裝外套兩側口袋與微腰身設計真的很美奶杏色天空藍共色草帽女孩圖簡約圖也是時髦穿搭的...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4004</th>\n",
              "      <td>男生染髮焦糖棕色質感低調的焦糖色讓男生頭髮也能有不一樣的選擇喜歡記得按讚追蹤並儲存焦糖棕色霧...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c6cabdf-0f3b-4569-b9bb-073f7615b031')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7c6cabdf-0f3b-4569-b9bb-073f7615b031 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7c6cabdf-0f3b-4569-b9bb-073f7615b031');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate validation metrics\n",
        "preds = test_df['prediction']\n",
        "labels = test_df['label']\n",
        "\n",
        "b_tp = sum([preds == labels and preds == 1 for preds, labels in zip(preds, labels)])\n",
        "b_fp = sum([preds != labels and preds == 1 for preds, labels in zip(preds, labels)]) #false positive\n",
        "b_tn = sum([preds == labels and preds == 0 for preds, labels in zip(preds, labels)]) #true negative\n",
        "b_fn =  sum([preds != labels and preds == 0 for preds, labels in zip(preds, labels)])\n",
        "\n",
        "'''\n",
        "  Returns the following metrics:\n",
        "    - accuracy    = (TP + TN) / N\n",
        "    - precision   = TP / (TP + FP)\n",
        "    - recall      = TP / (TP + FN)\n",
        "    - specificity = TN / (TN + FP)\n",
        "'''\n",
        "\n",
        "test_accuracy = (b_tp + b_tn) / len(labels)\n",
        "test_precision = b_tp / (b_tp + b_fp) if (b_tp + b_fp) > 0 else 'nan'\n",
        "test_recall = b_tp / (b_tp + b_fn) if (b_tp + b_fn) > 0 else 'nan'\n",
        "test_specificity = b_tn / (b_tn + b_fp) if (b_tn + b_fp) > 0 else 'nan'\n",
        "\n",
        "print(f'test_accuracy: {test_accuracy}')\n",
        "print(f'test_precision: {test_precision}')\n",
        "print(f'test_recall: {test_recall}')\n",
        "print(f'test_specificity: {test_specificity}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v___pIqBrwVx",
        "outputId": "10462d13-cfb2-4c62-8a19-e14bd7ce916a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_accuracy: 0.863\n",
            "test_precision: 0.8532289628180039\n",
            "test_recall: 0.8755020080321285\n",
            "test_specificity: 0.850597609561753\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ErPPSbnZmMc4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}